# 数据结构和算法之美
1. 从广义上讲，数据结构就是指一组数据的存储结构。算法就是操作数据的一组方法。
2. 那数据结构和算法有什么关系呢？为什么大部分书都把这两个东西放到一块儿来讲呢？这是因为，数据结构和算法是相辅相成的。数据结构是为算法服务的，算法要作用在特定的数据结构之上。因此，我们无法孤立数据结构来讲算法，也无法孤立算法来讲数据结构。
## 一.学习技巧
1. 边学边练，适度刷题（leedcode）
2. 多问，多思考，多互动
3. 打怪升级法（每阶段的成就感会促进更好的投入学习）
4. 知识需要沉淀，不要想试图一下子掌握所有（普通人需要反复的学习才能掌握）
## 二.线性表
### 数组
1. 支持随机查找，根据下标的查找的时间复杂度O(1),新增删除的平时时间复杂度O(n),最好时间复杂度O(1),最坏时间复杂度O(n)
2. 和java的ArrayList对比
- ArrayList相比数据最大优势是可以将很多数组操作的细节封装起来还有支持动态扩容
- ArrayList不支持存储基本类型
- 数据大小事先已知，并且数组的操作简单用不到大部分的ArrayList方法，也可以直接使用数据
- 表示多维数据时使用数组更直观
- 为什么数组要从0开始编号？从0开始编号的a[k]的内存公式是a[k]_address=base_address+k*type_size。从1开始编号的a[k]的内存公式是a[k]_address=base_address+（k-1）*type_size。从1开始编号要比从0开始编号多运算一次。
### 链表
1. 分类：单链表，循环链表，双向链表
双向链表在插入删除节点时会比单向列表高效（例如：删除给定节点时双向链表不用在遍历一遍查出给定节点的前节点）（LinkedHashMap就是双向节点）
2. 和数组对比
- 数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读。
- 链表没有大小的限制，数组需要通过复制到新数组进行扩容。
- 链表更加消耗内存（需要存下一个节点的指针），容易造成内存碎片。

| 操作\时间复杂度\数据结构 | 数组 | 链表 |
| ------------- |:-------------:| -----:|
| 插入删除 | O(n) | O(1) |
| 随机查找 | O(1) | O(n) |
3. 技巧
- 重点留意边界条件处理
- 利用哨兵简化实现难度，优化性能
### 栈
栈是一种操作受限的数据结构，只支持出栈入栈。时间复杂度为O(1)。队列最大的特点就是先进先出，主要的两个操作是入队和出队。
1. 基于链表的实现方式，可以实现一个支持无限排队的无界队列（unbounded queue），但是可能会导致过多的请求等等，请求处理的响应时间过长。所以，针对响应时间比较敏感的系统，基于链表实现的无限排队的线程池是不合适的。
2. 而基于数组实现的有界队列（bounded queue），队列的大小有限，所以线程池中排队的请求超过队列大小时，接下来的请求就会被拒绝，这种方式对响应时间敏感的系统来说，就相对更加合理。不过，设置一个合理的队列大小，也是非常有讲究的。队列太大导致等待的请求太多，队列太小会导致无法充分利用系统资源、发挥最大性能。
3. 对于大部分资源有限的场景，当没有空闲资源时，基本上都可以通过“队列”这种数据结构来实现请求排队。
4. 队列是不是阻塞，并发，大小是否有限
### 队列
队列跟栈一样，也是一种抽象的数据结构。它具有先进先出的特性，支持在队尾插入元素，在队头删除元素。跟栈一样，队列可以用数组来实现，也可以用链表来实现。用数组实现的栈叫作顺序栈，用链表实现的栈叫作链式栈。同样，用数组实现的队列叫作顺序队列，用链表实现的队列叫作链式队列。
1. 基于链表的实现方式，可以实现一个支持无限排队的无界队列（unbounded queue），但是可能会导致过多的请求排队等待，请求处理的响应时间过长。所以，针对响应时间比较敏感的系统，基于链表实现的无限排队的线程池是不合适的。
2. 基于数组实现的有界队列（bounded queue），队列的大小有限，所以线程池中排队的请求超过队列大小时，接下来的请求就会被拒绝，这种方式对响应时间敏感的系统来说，就相对更加合理。不过，设置一个合理的队列大小，也是非常有讲究的。队列太大导致等待的请求太多，队列太小会导致无法充分利用系统资源、发挥最大性能。
3. 阻塞队列其实就是在队列基础上增加了阻塞操作。简单来说，就是在队列为空的时候，从队头取数据会被阻塞。因为此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回。
4. 线程安全的队列我们叫作并发队列
### 跳表
1. 跳表使用空间换时间的设计思路，通过构建多级索引来提高查询的效率，实现了基于链表的“二分查找”。跳表是一种动态数据结构，支持快速的插入、删除、查找操作，时间复杂度都是 O(logn)。
2. 跳表的空间复杂度是 O(n)。不过，跳表的实现非常灵活，可以通过改变索引构建策略，有效平衡执行效率和内存消耗。虽然跳表的代码实现并不简单，但是作为一种动态数据结构，比起红黑树来说，实现要简单多了,而且按照区间查找效率更高。所以很多时候，我们为了代码的简单、易读，比起红黑树，我们更倾向用跳表。
## 三.排序
![snapshot](./排序.jpg)
1. 如何分析一个排序算法？
- 学习排序算法的思路？明确原理、掌握实现以及分析性能。
- 如何分析排序算法性能？从执行效率、内存消耗以及稳定性3个方面分析排序算法的性能。
- 执行效率：从以下3个方面来衡量
  + 最好情况、最坏情况、平均情况时间复杂度
  + 时间复杂度的系数、常数、低阶：排序的数据量比较小时考虑
  + 比较次数和交换（或移动）次数
- 内存消耗：通过空间复杂度来衡量。针对排序算法的空间复杂度，引入原地排序的概念，原地排序算法就是指空间复杂度为O(1)的排序算法。
- 稳定性：如果待排序的序列中存在值等的元素，经过排序之后，相等元素之间原有的先后顺序不变，就说明这个排序算法时稳定的。
2. 备注
- 可以通过有序度和逆序度来算平均时间复杂度
  + 例如：“有序度”和“逆序度”：对于一个不完全有序的数组，如4，5，6，3，2，1，有序元素对为3个（4，5），（4，6），（5，6），有序度为3，逆序度为12；对于一个完全有序的数组，如1，2，3，4，5，6，有序度就是n*(n-1)/2，也就是15，称作满有序度；逆序度=满有序度-有序度；冒泡排序、插入排序交换（或移动）次数=逆序度。最好情况下初始有序度为n*(n-1)/2，最坏情况下初始有序度为0，则平均初始有序度为n*(n-1)/
- 选择排序算法是不稳定算法，冒泡和插入排序是稳定算法
3. 思考
- 选择排序和插入排序的时间复杂度相同，都是O(n^2)，在实际的软件开发中，为什么我们更倾向于使用插入排序而不是冒泡排序算法呢？
  + 从代码实现上来看，冒泡排序的数据交换要比插入排序的数据移动要复杂，冒泡排序需要3个赋值操作，而插入排序只需要1个，所以在对相同数组进行排序时，冒泡排序的运行时间理论上要长于插入排序。
- 归并排序算法是一种在任何情况下时间复杂度都比较稳定的排序算法，这也使它存在致命的缺点，即归并排序不是原地排序算法，空间复杂度比较高，是 O(n)。正因为此，它也没有快排应用广泛。
  + 写递归代码的技巧就是，分析得出递推公式，然后找到终止条件，最后将递推公式翻译成递归代码。所以，要想写出归并排序的代码，我们先写出归并排序的递推公式。
  + 递推公式：merge_sort(p…r) = merge(merge_sort(p…q), merge_sort(q+1…r))
  + 终止条件：p >= r 不用再继续分解
- 快速排序算法虽然最坏情况下的时间复杂度是 O(n2)，但是平均情况下时间复杂度都是 O(nlogn)。不仅如此，快速排序算法时间复杂度退化到 O(n2) 的概率非常小，我们可以通过合理地选择 pivot 来避免这种情况。
  + 三数取中法。如果要排序的数组比较大，那“三数取中”可能就不够了，可能要“五数取中”或者“十数取中”。
  + 随机法。时间复杂度退化为最糟糕的 O(n2) 的情况，出现的可能性不大。
- 计数排序只能用在数据范围不大的场景中，如果数据范围 k 比要要排序的数据 n 大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数。
- 基数排序对要排序的数据是有要求的，需要可以分割出独立的“位”来比较，而且位之间有递进的关系，如果 a 数据的高位比 b 数据大，那剩下的低位就不用比较了。除此之外，每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到 O(n) 了。
- 桶排序，顾名思义，会用到“桶”，核心思想是将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。桶排序比较适合用在外部排序中。所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。桶排序有如下要求：
  + 要排序的数据需要很容易就能划分成 m 个桶
  + 数据在各个桶之间的分布是比较均匀的
## 四.二分查找
- 二分查找依赖的是顺序表结构，简单点说就是数组。其次，二分查找针对的是有序数据。再次，数据量太小不适合二分查找。最后，数据量太大也不适合二分查找。
- 凡是用二分查找能解决的，绝大部分我们更倾向于用散列表或者二叉查找树
- 值等于给定值”的二分查找确实不怎么会被用到，二分查找更适合用在“近似”查找问题，在这类问题上，二分查找的优势更加明显。
## 五.二叉数
![snapshot](./二叉数高度深度层.jpg)
![snapshot](./二叉数遍历.jpg)
- 二叉树既可以用链式存储，也可以用数组顺序存储。数组顺序存储的方式比较适合完全二叉树，其他类型的二叉树用数组存储会比较浪费存储空间。除此之外，二叉树里非常重要的操作就是前、中、后序遍历操作，遍历的时间复杂度是 O(n)，你需要理解并能用递归代码来实现。
- 有了如此高效的散列表，为什么还需要二叉树？
  + 散列表中的数据是无序存储的，如果要输出有序的数据，需要先进行排序。而对于二叉查找树来说，我们只需要中序遍历，就可以在 O(n) 的时间复杂度内，输出有序的数据序列。
  + 散列表扩容耗时很多，而且当遇到散列冲突时，性能不稳定，，尽管二叉查找树的性能不稳定，但是在工程中，我们最常用的平衡二叉查找树的性能非常稳定，时间复杂度稳定在 O(logn)。
  + 笼统地来说，尽管散列表的查找等操作的时间复杂度是常量级，但因为哈希冲突的存在，这个常量不一定比 logn 小，所以实际的查找速度可能不一定比 O(logn) 快。加上哈希函数的耗时，也不一定就比平衡二叉查找树的效率高。
  + 散列表的构造比二叉查找树要复杂，需要考虑的东西很多。比如散列函数的设计、冲突解决办法、扩容、缩容等。平衡二叉查找树只需要考虑平衡性这一个问题，而且这个问题的解决方案比较成熟、固定。
  + 为了避免过多的散列冲突，散列表装载因子不能太大，特别是基于开放寻址法解决冲突的散列表，会浪费一定的存储空间。
## 红黑树
- 红黑树是一种平衡二叉查找树。它是为了解决普通二叉查找树在数据更新的过程中，复杂度退化的问题而产生的。红黑树的高度近似 log2n，所以它是近似平衡，插入、删除、查找操作的时间复杂都是 O(logn)。
  + 根节点为黑色
  + 所有叶子节点为黑色，且不存储数据
  + 相邻两个节点不能都为红色
  + 从某节点到其所有叶子节点的路径中，黑色节点数相同
- 红黑树是一种性能非常稳定的二叉查找树，所以，在工程中，但凡是动态插入、删除、查找数据的场景，都可以用到它。
  + 平衡二叉树的严格定义是这样的：二叉树中任意一个节点的左右子树的高度相差不能大于 1
  +  红黑树只是做到了近似平衡，并不是严格的平衡，所以在维护平衡的成本上，要比 AVL 树要低。
  + AVL 树是一种高度平衡的二叉树，所以查找的效率非常高，但是，有利就有弊，AVL 树为了维持这种高度的平衡，就要付出更多代价。每次插入、删除都要做调整，就比较复杂、耗时。所以，对于有频繁的插入、删除操作的数据集合，使用 AVL 树的代价就有点高了。
## 递归
- 递归是一种非常高效、简洁的编码技巧，一种应用非常广泛的算法，比如DFS深度优先搜索、前中后序二叉树遍历等都是使用递归。
- 方法或函数调用自身的方式称为递归调用，调用称为递，返回称为归。
- 基本上，所有的递归问题都可以用递推公式来表示，比如
  + f(n) = f(n-1) + 1; 
  + f(n) = f(n-1) + f(n-2);
  + f(n)=n*f(n-1);
- 优缺点
  + 优点：代码的表达力很强，写起来简洁
  + 缺点：空间复杂度高、有堆栈溢出风险、存在重复计算、过多的函数调用会耗时较多等问题。
- 一个问题只要同时满足以下3个条件，就可以用递归来解决
  + 问题的解可以分解为几个子问题的解。何为子问题？就是数据规模更小的问题
  + 问题与子问题，除了数据规模不同，求解思路完全一样
  + 存在递归终止条件
- 实现递归
  + 编写:写递归代码的关键就是找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后再推敲终止条件，最后将递推公式和终止条件翻译成代码。
  + 理解:对于递归代码，若试图想清楚整个递和归的过程，实际上是进入了一个思维误区。那该如何理解递归代码呢？如果一个问题A可以分解为若干个子问题B、C、D，你可以假设子问题B、C、D已经解决。而且，你只需要思考问题A与子问题B、C、D两层之间的关系即可，不需要一层层往下思考子问题与子子问题，子子问题与子子子问题之间的关系。屏蔽掉递归细节，这样子理解起来就简单多了。因此，理解递归代码，就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。
- 递归常见问题及解决方案
  + 警惕堆栈溢出：可以声明一个全局变量来控制递归的深度，从而避免堆栈溢出。
  + 警惕重复计算：通过某种数据结构来保存已经求解过的值，从而避免重复计算。
## 分治思想
1. 分治，顾名思义，就是分而治之，将一个大问题分解成小的子问题来解决。小的子问题解决了，大问题也就解决了。
2. 分治思想跟我们前面讲的递归思想很像。是的，分治算法一般都是用递归来实现的。分治是一种解决问题的处理思想，递归是一种编程技巧，这两者并不冲突


---
![snapshot](./算法知识图片.jpg)